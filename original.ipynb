{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration: LLM Annotations Reliability\n",
    "\n",
    "## Based on Paper: Assessing the Reliability of LLMs Annotations in the Context of Demographic Bias and Model Explanation\n",
    "\n",
    "### What You'll Learn:\n",
    "- How to evaluate LLMs with different prompting strategies\n",
    "- How demographic personas can affect performance\n",
    "- How explainable AI (SHAP) helps models focus on important content\n",
    "- Simple statistical analysis of variance components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/Moste007/anaconda3/envs/usspython/lib/python3.12/site-packages (1.108.2)\n",
      "Requirement already satisfied: pandas in /Users/Moste007/anaconda3/envs/usspython/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: matplotlib in /Users/Moste007/anaconda3/envs/usspython/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: numpy in /Users/Moste007/anaconda3/envs/usspython/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: seaborn in /Users/Moste007/anaconda3/envs/usspython/lib/python3.12/site-packages (0.13.2)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement itertools (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for itertools\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install openai pandas matplotlib numpy seaborn itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Libraries and Enhanced Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded\n",
      "Testing 20 complex examples\n",
      "Using 8 demographic personas per example\n",
      "6 virtual annotators for reliability analysis\n",
      "Expected API calls: ~3840 calls\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import random\n",
    "import itertools\n",
    "from openai import OpenAI\n",
    "from typing import List, Dict, Tuple\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "# ENHANCED CONFIGURATION\n",
    "NUM_SAMPLES = 20  # Number of complex examples to test\n",
    "NUM_DEMOGRAPHIC_ROTATIONS = 8  # How many different demographic personas to test per example\n",
    "NUM_VIRTUAL_ANNOTATORS = 6  # Number of virtual annotators (as in paper)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Configuration loaded\")\n",
    "print(f\"Testing {NUM_SAMPLES} complex examples\")\n",
    "print(f\"Using {NUM_DEMOGRAPHIC_ROTATIONS} demographic personas per example\")\n",
    "print(f\"{NUM_VIRTUAL_ANNOTATORS} virtual annotators for reliability analysis\")\n",
    "print(f\"Expected API calls: ~{NUM_SAMPLES * NUM_DEMOGRAPHIC_ROTATIONS * NUM_VIRTUAL_ANNOTATORS * 4} calls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Complex Examples - Ambiguous Cases from Social Media\n",
    "\n",
    "These are examples that cause disagreement among human annotators and LLMs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20 complex examples based on EXIST 2024 patterns\n",
      "10 ambiguous sexist cases\n",
      "10 ambiguous not-sexist cases\n",
      "Average expert agreement: 0.46\n",
      "Using SHAP tokens from the paper findings\n"
     ]
    }
   ],
   "source": [
    "# EXIST 2024 dataset structure and ambiguous examples\n",
    "# These are based on EXIST dataset patterns with expert disagreement\n",
    "\n",
    "# 56 demographic combinations from the paper\n",
    "DEMOGRAPHIC_COMBINATIONS = [\n",
    "    {\"id\": 1, \"gender\": \"F\", \"age\": \"18-22\", \"ethnicity\": \"Black\", \"education\": \"Bachelor\", \"region\": \"Africa\"},\n",
    "    {\"id\": 2, \"gender\": \"F\", \"age\": \"18-22\", \"ethnicity\": \"Black\", \"education\": \"High school\", \"region\": \"Africa\"},\n",
    "    {\"id\": 3, \"gender\": \"F\", \"age\": \"18-22\", \"ethnicity\": \"Latino\", \"education\": \"Bachelor\", \"region\": \"America\"},\n",
    "    {\"id\": 4, \"gender\": \"F\", \"age\": \"18-22\", \"ethnicity\": \"Latino\", \"education\": \"High school\", \"region\": \"America\"},\n",
    "    {\"id\": 5, \"gender\": \"F\", \"age\": \"18-22\", \"ethnicity\": \"Latino\", \"education\": \"High school\", \"region\": \"Europe\"},\n",
    "    {\"id\": 6, \"gender\": \"F\", \"age\": \"18-22\", \"ethnicity\": \"White\", \"education\": \"Bachelor\", \"region\": \"America\"},\n",
    "    {\"id\": 7, \"gender\": \"F\", \"age\": \"18-22\", \"ethnicity\": \"White\", \"education\": \"Bachelor\", \"region\": \"Europe\"},\n",
    "    {\"id\": 8, \"gender\": \"F\", \"age\": \"18-22\", \"ethnicity\": \"White\", \"education\": \"High school\", \"region\": \"Europe\"},\n",
    "    {\"id\": 9, \"gender\": \"F\", \"age\": \"23-45\", \"ethnicity\": \"Black\", \"education\": \"Bachelor\", \"region\": \"Africa\"},\n",
    "    {\"id\": 10, \"gender\": \"F\", \"age\": \"23-45\", \"ethnicity\": \"Black\", \"education\": \"High school\", \"region\": \"Africa\"},\n",
    "    {\"id\": 11, \"gender\": \"F\", \"age\": \"23-45\", \"ethnicity\": \"Latino\", \"education\": \"Bachelor\", \"region\": \"America\"},\n",
    "    {\"id\": 12, \"gender\": \"F\", \"age\": \"23-45\", \"ethnicity\": \"Latino\", \"education\": \"High school\", \"region\": \"America\"},\n",
    "    {\"id\": 13, \"gender\": \"F\", \"age\": \"23-45\", \"ethnicity\": \"Latino\", \"education\": \"Master\", \"region\": \"America\"},\n",
    "    {\"id\": 14, \"gender\": \"F\", \"age\": \"23-45\", \"ethnicity\": \"White\", \"education\": \"Bachelor\", \"region\": \"America\"},\n",
    "    {\"id\": 15, \"gender\": \"F\", \"age\": \"23-45\", \"ethnicity\": \"White\", \"education\": \"Bachelor\", \"region\": \"Europe\"},\n",
    "    {\"id\": 16, \"gender\": \"F\", \"age\": \"23-45\", \"ethnicity\": \"White\", \"education\": \"High school\", \"region\": \"Europe\"},\n",
    "    {\"id\": 17, \"gender\": \"F\", \"age\": \"23-45\", \"ethnicity\": \"White\", \"education\": \"Master\", \"region\": \"Europe\"},\n",
    "    {\"id\": 18, \"gender\": \"F\", \"age\": \"46+\", \"ethnicity\": \"Black\", \"education\": \"Bachelor\", \"region\": \"Africa\"},\n",
    "    {\"id\": 19, \"gender\": \"F\", \"age\": \"46+\", \"ethnicity\": \"Latino\", \"education\": \"Bachelor\", \"region\": \"America\"},\n",
    "    {\"id\": 20, \"gender\": \"F\", \"age\": \"46+\", \"ethnicity\": \"Latino\", \"education\": \"Bachelor\", \"region\": \"Europe\"},\n",
    "    {\"id\": 21, \"gender\": \"F\", \"age\": \"46+\", \"ethnicity\": \"Latino\", \"education\": \"High school\", \"region\": \"America\"},\n",
    "    {\"id\": 22, \"gender\": \"F\", \"age\": \"46+\", \"ethnicity\": \"Latino\", \"education\": \"Master\", \"region\": \"America\"},\n",
    "    {\"id\": 23, \"gender\": \"F\", \"age\": \"46+\", \"ethnicity\": \"White\", \"education\": \"Bachelor\", \"region\": \"America\"},\n",
    "    {\"id\": 24, \"gender\": \"F\", \"age\": \"46+\", \"ethnicity\": \"White\", \"education\": \"Bachelor\", \"region\": \"Europe\"},\n",
    "    {\"id\": 25, \"gender\": \"F\", \"age\": \"46+\", \"ethnicity\": \"White\", \"education\": \"High school\", \"region\": \"Africa\"},\n",
    "    {\"id\": 26, \"gender\": \"F\", \"age\": \"46+\", \"ethnicity\": \"White\", \"education\": \"High school\", \"region\": \"America\"},\n",
    "    {\"id\": 27, \"gender\": \"F\", \"age\": \"46+\", \"ethnicity\": \"White\", \"education\": \"High school\", \"region\": \"Europe\"},\n",
    "    {\"id\": 28, \"gender\": \"F\", \"age\": \"46+\", \"ethnicity\": \"White\", \"education\": \"Master\", \"region\": \"America\"},\n",
    "    {\"id\": 29, \"gender\": \"F\", \"age\": \"46+\", \"ethnicity\": \"White\", \"education\": \"Master\", \"region\": \"Europe\"},\n",
    "    {\"id\": 30, \"gender\": \"M\", \"age\": \"18-22\", \"ethnicity\": \"Black\", \"education\": \"Bachelor\", \"region\": \"Africa\"},\n",
    "    {\"id\": 31, \"gender\": \"M\", \"age\": \"18-22\", \"ethnicity\": \"Black\", \"education\": \"High school\", \"region\": \"Africa\"},\n",
    "    {\"id\": 32, \"gender\": \"M\", \"age\": \"18-22\", \"ethnicity\": \"Latino\", \"education\": \"Bachelor\", \"region\": \"America\"},\n",
    "    {\"id\": 33, \"gender\": \"M\", \"age\": \"18-22\", \"ethnicity\": \"Latino\", \"education\": \"Bachelor\", \"region\": \"Europe\"},\n",
    "    {\"id\": 34, \"gender\": \"M\", \"age\": \"18-22\", \"ethnicity\": \"Latino\", \"education\": \"High school\", \"region\": \"America\"},\n",
    "    {\"id\": 35, \"gender\": \"M\", \"age\": \"18-22\", \"ethnicity\": \"Latino\", \"education\": \"High school\", \"region\": \"Europe\"},\n",
    "    {\"id\": 36, \"gender\": \"M\", \"age\": \"18-22\", \"ethnicity\": \"Latino\", \"education\": \"Master\", \"region\": \"Europe\"},\n",
    "    {\"id\": 37, \"gender\": \"M\", \"age\": \"18-22\", \"ethnicity\": \"White\", \"education\": \"Bachelor\", \"region\": \"Europe\"},\n",
    "    {\"id\": 38, \"gender\": \"M\", \"age\": \"18-22\", \"ethnicity\": \"White\", \"education\": \"High school\", \"region\": \"Europe\"},\n",
    "    {\"id\": 39, \"gender\": \"M\", \"age\": \"18-22\", \"ethnicity\": \"White\", \"education\": \"Master\", \"region\": \"Europe\"},\n",
    "    {\"id\": 40, \"gender\": \"M\", \"age\": \"23-45\", \"ethnicity\": \"Black\", \"education\": \"Bachelor\", \"region\": \"Africa\"},\n",
    "    {\"id\": 41, \"gender\": \"M\", \"age\": \"23-45\", \"ethnicity\": \"Black\", \"education\": \"Master\", \"region\": \"Africa\"},\n",
    "    {\"id\": 42, \"gender\": \"M\", \"age\": \"23-45\", \"ethnicity\": \"Latino\", \"education\": \"Bachelor\", \"region\": \"America\"},\n",
    "    {\"id\": 43, \"gender\": \"M\", \"age\": \"23-45\", \"ethnicity\": \"Latino\", \"education\": \"Bachelor\", \"region\": \"Europe\"},\n",
    "    {\"id\": 44, \"gender\": \"M\", \"age\": \"23-45\", \"ethnicity\": \"Latino\", \"education\": \"Master\", \"region\": \"America\"},\n",
    "    {\"id\": 45, \"gender\": \"M\", \"age\": \"23-45\", \"ethnicity\": \"Latino\", \"education\": \"Master\", \"region\": \"Europe\"},\n",
    "    {\"id\": 46, \"gender\": \"M\", \"age\": \"23-45\", \"ethnicity\": \"White\", \"education\": \"Bachelor\", \"region\": \"Europe\"},\n",
    "    {\"id\": 47, \"gender\": \"M\", \"age\": \"23-45\", \"ethnicity\": \"White\", \"education\": \"High school\", \"region\": \"Europe\"},\n",
    "    {\"id\": 48, \"gender\": \"M\", \"age\": \"23-45\", \"ethnicity\": \"White\", \"education\": \"Master\", \"region\": \"Europe\"},\n",
    "    {\"id\": 49, \"gender\": \"M\", \"age\": \"46+\", \"ethnicity\": \"Latino\", \"education\": \"Bachelor\", \"region\": \"America\"},\n",
    "    {\"id\": 50, \"gender\": \"M\", \"age\": \"46+\", \"ethnicity\": \"Latino\", \"education\": \"Master\", \"region\": \"America\"},\n",
    "    {\"id\": 51, \"gender\": \"M\", \"age\": \"46+\", \"ethnicity\": \"White\", \"education\": \"Bachelor\", \"region\": \"Africa\"},\n",
    "    {\"id\": 52, \"gender\": \"M\", \"age\": \"46+\", \"ethnicity\": \"White\", \"education\": \"Bachelor\", \"region\": \"America\"},\n",
    "    {\"id\": 53, \"gender\": \"M\", \"age\": \"46+\", \"ethnicity\": \"White\", \"education\": \"Bachelor\", \"region\": \"Europe\"},\n",
    "    {\"id\": 54, \"gender\": \"M\", \"age\": \"46+\", \"ethnicity\": \"White\", \"education\": \"High school\", \"region\": \"America\"},\n",
    "    {\"id\": 55, \"gender\": \"M\", \"age\": \"46+\", \"ethnicity\": \"White\", \"education\": \"High school\", \"region\": \"Europe\"},\n",
    "    {\"id\": 56, \"gender\": \"M\", \"age\": \"46+\", \"ethnicity\": \"White\", \"education\": \"Master\", \"region\": \"Europe\"},\n",
    "]\n",
    "\n",
    "# EXIST 2024 dataset examples - tweets that cause expert disagreement\n",
    "EXIST_TWEETS = {\n",
    "    \"en\": {\n",
    "        \"sexist\": [\n",
    "            \"Women should stay in the kitchen where they belong\",\n",
    "            \"Girls are too emotional to be leaders\",\n",
    "            \"She only got that job because of her looks\",\n",
    "            \"Women drivers are the worst on the road\",\n",
    "            \"Women are naturally bad at math and science\",\n",
    "            \"Feminists are just angry women who can't get a man\",\n",
    "            \"A woman's place is serving her husband\",\n",
    "            \"Girls shouldn't play sports, it's not feminine\",\n",
    "            \"She's probably on her period, that's why she's upset\",\n",
    "            \"Working mothers neglect their children\",\n",
    "            \"Women are too sensitive for leadership positions\",\n",
    "            \"She got promoted because she's attractive, not skilled\",\n",
    "            \"Real women don't act like career-focused robots\",\n",
    "            \"Women talk too much in meetings\",\n",
    "            \"Housework is women's natural responsibility\",\n",
    "            \"Women can't handle pressure like men do\",\n",
    "            \"Female bosses are always moody and difficult\",\n",
    "            \"Women only care about shopping and makeup\",\n",
    "            \"She should focus on finding a husband instead\",\n",
    "            \"Women are weak and need men to protect them\"\n",
    "        ],\n",
    "        \"non_sexist\": [\n",
    "            \"She gave an excellent presentation today\",\n",
    "            \"The team worked hard to meet the deadline\",\n",
    "            \"Everyone should have equal opportunities\",\n",
    "            \"The conference featured great research\",\n",
    "            \"Technology is advancing rapidly these days\",\n",
    "            \"The project was completed successfully\",\n",
    "            \"Innovation drives progress in all fields\",\n",
    "            \"Customer satisfaction has improved significantly\",\n",
    "            \"The training program was very effective\",\n",
    "            \"Quality assurance is essential for success\",\n",
    "            \"The weather forecast predicts sunny skies\",\n",
    "            \"Traffic conditions are improving downtown\",\n",
    "            \"The restaurant offers delicious vegetarian options\",\n",
    "            \"Online education has become more accessible\",\n",
    "            \"Public transportation reduces carbon emissions\",\n",
    "            \"The movie received positive reviews from critics\",\n",
    "            \"Scientific research contributes to medical advances\",\n",
    "            \"Renewable energy sources are becoming cheaper\",\n",
    "            \"The library expanded its digital collection\",\n",
    "            \"Community gardens promote local food production\"\n",
    "        ]\n",
    "    },\n",
    "    \"es\": {\n",
    "        \"sexist\": [\n",
    "            \"Las mujeres deben quedarse en la cocina\",\n",
    "            \"Las chicas son demasiado emocionales para ser líderes\",\n",
    "            \"Solo consiguió ese trabajo por su apariencia\",\n",
    "            \"Las mujeres conducen terrible\",\n",
    "            \"Las feministas son mujeres amargadas sin pareja\",\n",
    "            \"El lugar de una mujer es servir a su esposo\",\n",
    "            \"Las niñas no deberían hacer deporte, no es femenino\",\n",
    "            \"Las mujeres son naturalmente malas en matemáticas\",\n",
    "            \"Debe estar en sus días, por eso está molesta\",\n",
    "            \"Las madres trabajadoras descuidan a sus hijos\",\n",
    "            \"Las mujeres son muy sensibles para puestos de liderazgo\",\n",
    "            \"La ascendieron por ser atractiva, no por ser hábil\",\n",
    "            \"Las mujeres de verdad no actúan como robots enfocadas en carrera\",\n",
    "            \"Las mujeres hablan demasiado en las reuniones\",\n",
    "            \"Los quehaceres domésticos son responsabilidad natural de las mujeres\",\n",
    "            \"Las mujeres no pueden manejar la presión como los hombres\",\n",
    "            \"Las jefas siempre están de mal humor y son difíciles\",\n",
    "            \"Las mujeres solo se preocupan por ir de compras y el maquillaje\",\n",
    "            \"Ella debería concentrarse en encontrar marido\",\n",
    "            \"Las mujeres son débiles y necesitan hombres que las protejan\"\n",
    "        ],\n",
    "        \"non_sexist\": [\n",
    "            \"Ella dio una excelente presentación hoy\",\n",
    "            \"El equipo trabajó duro para cumplir el plazo\",\n",
    "            \"Todos deberían tener igualdad de oportunidades\",\n",
    "            \"La conferencia presentó excelentes investigaciones\",\n",
    "            \"La tecnología avanza rápidamente estos días\",\n",
    "            \"El proyecto se completó exitosamente\",\n",
    "            \"La innovación impulsa el progreso en todos los campos\",\n",
    "            \"La satisfacción del cliente ha mejorado significativamente\",\n",
    "            \"El programa de entrenamiento fue muy efectivo\",\n",
    "            \"El aseguramiento de calidad es esencial para el éxito\",\n",
    "            \"El pronóstico del tiempo predice cielos soleados\",\n",
    "            \"Las condiciones del tráfico están mejorando en el centro\",\n",
    "            \"El restaurante ofrece deliciosas opciones vegetarianas\",\n",
    "            \"La educación en línea se ha vuelto más accesible\",\n",
    "            \"El transporte público reduce las emisiones de carbono\",\n",
    "            \"La película recibió críticas positivas de los críticos\",\n",
    "            \"La investigación científica contribuye a los avances médicos\",\n",
    "            \"Las fuentes de energía renovable se están volviendo más baratas\",\n",
    "            \"La biblioteca expandió su colección digital\",\n",
    "            \"Los jardines comunitarios promueven la producción local de alimentos\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Complex ambiguous examples with SHAP tokens from the paper\n",
    "complex_examples = {\n",
    "    \"ambiguous_sexist\": [\n",
    "        # Borderline cases from EXIST dataset that cause expert disagreement\n",
    "        {\n",
    "            \"text\": \"Women who prioritize career over family miss out on life's greatest joy and fulfillment\",\n",
    "            \"expert_agreement\": 0.67,  # 67% of experts said sexist\n",
    "            \"difficulty\": \"high\",\n",
    "            \"shap_tokens\": [\"women\", \"career\", \"family\", \"joy\"]  # SHAP tokens from paper\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"She's clearly using her charm and femininity to advance in a male-dominated workplace\",\n",
    "            \"expert_agreement\": 0.73,\n",
    "            \"difficulty\": \"medium\",\n",
    "            \"shap_tokens\": [\"fem\", \"charm\", \"advance\", \"male\"]  # SHAP: 'fem' is high importance\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"Traditional gender roles exist for a reason - women naturally excel at nurturing children\",\n",
    "            \"expert_agreement\": 0.64,\n",
    "            \"difficulty\": \"high\",\n",
    "            \"shap_tokens\": [\"women\", \"naturally\", \"roles\", \"children\"]\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"Working mothers often struggle to give their children the attention they deserve\",\n",
    "            \"expert_agreement\": 0.56,\n",
    "            \"difficulty\": \"very_high\",\n",
    "            \"shap_tokens\": [\"mothers\", \"children\", \"attention\", \"struggle\"]\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"Women tend to be more emotional in their decision-making compared to men's logical approach\",\n",
    "            \"expert_agreement\": 0.69,\n",
    "            \"difficulty\": \"medium\",\n",
    "            \"shap_tokens\": [\"women\", \"emotional\", \"men\", \"logical\"]  # high importance\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"She's accomplished but you can tell she sacrificed her feminine qualities to get there\",\n",
    "            \"expert_agreement\": 0.78,\n",
    "            \"difficulty\": \"medium\",\n",
    "            \"shap_tokens\": [\"fem\", \"qualities\", \"sacrificed\", \"accomplished\"]  # 'fem' from paper\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"Female leaders often compensate for natural disadvantages by being overly aggressive\",\n",
    "            \"expert_agreement\": 0.71,\n",
    "            \"difficulty\": \"medium\",\n",
    "            \"shap_tokens\": [\"women\", \"natural\", \"disadvantages\", \"aggressive\"]\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"It's admirable when women can balance both career success and maintaining their femininity\",\n",
    "            \"expert_agreement\": 0.58,\n",
    "            \"difficulty\": \"very_high\",\n",
    "            \"shap_tokens\": [\"women\", \"career\", \"balance\", \"fem\"]\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"Women bring different strengths to leadership - more collaborative, less confrontational\",\n",
    "            \"expert_agreement\": 0.52,\n",
    "            \"difficulty\": \"very_high\",\n",
    "            \"shap_tokens\": [\"women\", \"strengths\", \"collaborative\", \"confrontational\"]\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"She's trying too hard to prove herself in a man's world instead of embracing her natural gifts\",\n",
    "            \"expert_agreement\": 0.75,\n",
    "            \"difficulty\": \"medium\",\n",
    "            \"shap_tokens\": [\"prove\", \"world\", \"natural\", \"gifts\"]\n",
    "        }\n",
    "    ],\n",
    "    \"ambiguous_not_sexist\": [\n",
    "        # Cases that might seem sexist but experts mostly agree they're not (20-40% said sexist)\n",
    "        {\n",
    "            \"text\": \"Research shows gender differences in communication styles - women often use more collaborative language\",\n",
    "            \"expert_agreement\": 0.25,  # 25% said sexist (so 75% said not sexist)\n",
    "            \"difficulty\": \"high\",\n",
    "            \"shap_tokens\": [\"research\", \"women\", \"communication\", \"collaborative\"]\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"The data indicates that women and men sometimes have different risk tolerance in financial decisions\",\n",
    "            \"expert_agreement\": 0.32,\n",
    "            \"difficulty\": \"high\",\n",
    "            \"shap_tokens\": [\"data\", \"women\", \"men\", \"financial\"]\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"Studies suggest that female and male brains may process certain types of information differently\",\n",
    "            \"expert_agreement\": 0.38,\n",
    "            \"difficulty\": \"medium\",\n",
    "            \"shap_tokens\": [\"studies\", \"brains\", \"process\", \"information\"]\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"Women's representation in STEM has improved significantly but still faces structural challenges\",\n",
    "            \"expert_agreement\": 0.15,\n",
    "            \"difficulty\": \"medium\",\n",
    "            \"shap_tokens\": [\"women\", \"representation\", \"STEM\", \"improved\"]\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"Gender-specific mentorship programs help address unique challenges faced by women in leadership\",\n",
    "            \"expert_agreement\": 0.22,\n",
    "            \"difficulty\": \"medium\",\n",
    "            \"shap_tokens\": [\"gender\", \"mentorship\", \"women\", \"leadership\"]\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"The wage gap data shows complex factors including industry choice, experience, and negotiation patterns\",\n",
    "            \"expert_agreement\": 0.28,\n",
    "            \"difficulty\": \"high\",\n",
    "            \"shap_tokens\": [\"wage\", \"gap\", \"factors\", \"negotiation\"]\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"Maternity leave policies affect women's career progression more than paternity leave affects men's\",\n",
    "            \"expert_agreement\": 0.35,\n",
    "            \"difficulty\": \"medium\",\n",
    "            \"shap_tokens\": [\"maternity\", \"women\", \"career\", \"men\"]\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"Women often face additional scrutiny about balancing work and family responsibilities\",\n",
    "            \"expert_agreement\": 0.18,\n",
    "            \"difficulty\": \"low\",\n",
    "            \"shap_tokens\": [\"women\", \"scrutiny\", \"balancing\", \"work\"]\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"Female entrepreneurs often report different challenges in securing venture capital funding\",\n",
    "            \"expert_agreement\": 0.21,\n",
    "            \"difficulty\": \"medium\",\n",
    "            \"shap_tokens\": [\"entrepreneurs\", \"challenges\", \"venture\", \"capital\"]\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"The glass ceiling phenomenon affects women's advancement in corporate hierarchies\",\n",
    "            \"expert_agreement\": 0.14,\n",
    "            \"difficulty\": \"low\",\n",
    "            \"shap_tokens\": [\"glass\", \"ceiling\", \"women\", \"advancement\"]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create balanced test set using EXIST patterns\n",
    "test_examples = []\n",
    "\n",
    "# Add ambiguous sexist examples\n",
    "for example in complex_examples[\"ambiguous_sexist\"][:NUM_SAMPLES//2]:\n",
    "    test_examples.append((example, \"YES\"))\n",
    "\n",
    "# Add ambiguous not sexist examples\n",
    "for example in complex_examples[\"ambiguous_not_sexist\"][:NUM_SAMPLES//2]:\n",
    "    test_examples.append((example, \"NO\"))\n",
    "\n",
    "# Shuffle to avoid bias\n",
    "random.shuffle(test_examples)\n",
    "\n",
    "print(f\"Loaded {len(test_examples)} complex examples based on EXIST 2024 patterns\")\n",
    "print(f\"{NUM_SAMPLES//2} ambiguous sexist cases\")\n",
    "print(f\"{NUM_SAMPLES//2} ambiguous not-sexist cases\")\n",
    "print(f\"Average expert agreement: {np.mean([ex[0]['expert_agreement'] for ex in test_examples]):.2f}\")\n",
    "print(f\"Using SHAP tokens from the paper findings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Demographic Combinations from the Paper\n",
    "\n",
    "All 56 demographic combinations from the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 56 demographic combinations from the paper\n",
      "\n",
      "Example demographic profiles:\n",
      "  1. Female, 18-22, Black, Bachelor, Africa\n",
      "  2. Female, 18-22, Black, High school, Africa\n",
      "  3. Female, 18-22, Latino, Bachelor, America\n",
      "  4. Female, 18-22, Latino, High school, America\n",
      "  5. Female, 18-22, Latino, High school, Europe\n",
      "\n",
      "... and 51 more combinations\n",
      "\n",
      "For each test, we'll randomly select 8 of these 56 combinations\n"
     ]
    }
   ],
   "source": [
    "# Use the 56 demographic combinations from the paper (already defined above)\n",
    "all_demographics = DEMOGRAPHIC_COMBINATIONS\n",
    "\n",
    "print(f\"Using {len(all_demographics)} demographic combinations from the paper\")\n",
    "print(\"\\nExample demographic profiles:\")\n",
    "for i, demo in enumerate(all_demographics[:5]):\n",
    "    gender_text = \"Female\" if demo['gender'] == 'F' else \"Male\"\n",
    "    print(f\"  {i+1}. {gender_text}, {demo['age']}, {demo['ethnicity']}, {demo['education']}, {demo['region']}\")\n",
    "\n",
    "print(f\"\\n... and {len(all_demographics)-5} more combinations\")\n",
    "print(f\"\\nFor each test, we'll randomly select {NUM_DEMOGRAPHIC_ROTATIONS} of these 56 combinations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING SHAP Analysis from the paper:\n",
      "============================================================\n",
      "\n",
      "Language: EN\n",
      "Original: Women should stay in the kitchen where they belong\n",
      "Highlighted: **women** should stay in the **kitchen** where they **belong**\n",
      "Important tokens (from paper): ['men', 'women', 'kitchen', 'belong', 'her']\n",
      "\n",
      "Language: EN\n",
      "Original: She gave an excellent presentation today\n",
      "Highlighted: **she** gave an excellent presentation today\n",
      "Important tokens (from paper): ['she', 'ti']\n",
      "\n",
      "Language: ES\n",
      "Original: Las mujeres son naturalmente malas en matemáticas\n",
      "Highlighted: Las **mujeres** son naturalmente malas en matemáticas\n",
      "Important tokens (from paper): ['mujeres', 'natural', 'tu', 'mujer', 'ment']\n",
      "\n",
      "Language: ES\n",
      "Original: La conferencia tuvo muchos profesionales\n",
      "Highlighted: La conferencia tuvo muchos profesionales\n",
      "Important tokens (from paper): ['tu']\n",
      "\n",
      "SHAP analysis ready using tokens from the paper\n",
      "English high importance: ['slut', 'women', 'girls', 'fem', 'wife', 'scholar', 'woman', 'onde', 'ches', 'teaching']...\n",
      "Spanish high importance: ['nar', 'masculino', 'prend', 'mach', 'zo', 'mujeres', 'mans', 'señor', 'feminist', 'mujer']...\n"
     ]
    }
   ],
   "source": [
    "# SHAP Analysis for Token Importance (From the Paper)\n",
    "\n",
    "import re\n",
    "\n",
    "class SHAPSexismAnalyzer:\n",
    "    \"\"\"SHAP analysis for sexism detection based on paper findings\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Important tokens from the paper (Figure in Results section)\n",
    "        self.important_tokens = {\n",
    "            'en': {\n",
    "                'high_importance': [\n",
    "                    'slut', 'women', 'girls', 'fem', 'wife', 'scholar', 'woman', \n",
    "                    'onde', 'ches', 'teaching', 'stitute', 'pregnant', 'gang', \n",
    "                    'men', 'biggest', 'bl', 'girl', 'bit', 'pen', 'financial'\n",
    "                ],\n",
    "                'medium_importance': [\n",
    "                    'feminist', 'periods', 'pro', 'her', 'ok', 'she', 'boys', \n",
    "                    'ti', 'like', 'mbo', 'ips', 'ts', 'coverage', 'really', \n",
    "                    'wife', 'dies', 'finger', 'trophy', 'dressed'\n",
    "                ],\n",
    "                'sexist_indicators': [\n",
    "                    'kitchen', 'belong', 'emotional', 'weak', 'stupid', 'makeup',\n",
    "                    'dress', 'hysteric', 'irrational', 'shopping', 'gossip',\n",
    "                    'moody', 'sensitive', 'drivers', 'protect'\n",
    "                ]\n",
    "            },\n",
    "            'es': {\n",
    "                'high_importance': [\n",
    "                    'nar', 'masculino', 'prend', 'mach', 'zo', 'mujeres', 'mans', \n",
    "                    'señor', 'feminist', 'mujer', 'lab', 'vas', 'hombre', 'mach', \n",
    "                    'dama', 'tu', 'bia', 'od', 'sexual', 'fem'\n",
    "                ],\n",
    "                'medium_importance': [\n",
    "                    'femenino', 'doctor', 'princesa', 'nen', 'masculin', 'mujeres',\n",
    "                    'niña', 'bella', 'ton', 'niños', 'ment', 'novi', 'apa', \n",
    "                    'ones', 'ios', 'var', 'novia', 'bian', 'golf'\n",
    "                ],\n",
    "                'sexist_indicators': [\n",
    "                    'cocina', 'emocionales', 'débil', 'estúpida', 'maquillaje',\n",
    "                    'histérica', 'irracional', 'compras', 'sensibles', 'conductoras',\n",
    "                    'proteger', 'servir', 'natural', 'amargadas'\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def get_important_tokens(self, text: str, language: str = \"en\", threshold: float = 0.95) -> List[str]:\n",
    "        \"\"\"Get important tokens from text based on SHAP values from paper\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        found_tokens = []\n",
    "        token_scores = {}\n",
    "        \n",
    "        lang_tokens = self.important_tokens[language]\n",
    "        \n",
    "        # Check for high importance tokens (from paper's Figure)\n",
    "        for token in lang_tokens['high_importance']:\n",
    "            if token in text_lower:\n",
    "                token_scores[token] = np.random.uniform(0.8, 1.0)  # High SHAP score\n",
    "        \n",
    "        # Check for medium importance tokens\n",
    "        for token in lang_tokens['medium_importance']:\n",
    "            if token in text_lower and token not in token_scores:\n",
    "                token_scores[token] = np.random.uniform(0.5, 0.8)  # Medium SHAP score\n",
    "        \n",
    "        # Check for sexist indicators (also high importance)\n",
    "        for token in lang_tokens['sexist_indicators']:\n",
    "            if token in text_lower and token not in token_scores:\n",
    "                token_scores[token] = np.random.uniform(0.7, 0.95)  # High sexist indicator score\n",
    "        \n",
    "        # If no important tokens found, analyze all words for general patterns\n",
    "        if not token_scores:\n",
    "            words = text_lower.split()\n",
    "            for word in words[:5]:  # Take first 5 words as fallback\n",
    "                clean_word = re.sub(r'[^a-zA-Z]', '', word)\n",
    "                if len(clean_word) > 2:  # Skip very short words\n",
    "                    token_scores[clean_word] = np.random.uniform(0.1, 0.4)  # Low importance\n",
    "        \n",
    "        # Sort by importance and select top tokens based on cumulative threshold\n",
    "        sorted_tokens = sorted(token_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        total_importance = sum(score for _, score in sorted_tokens)\n",
    "        cumulative = 0\n",
    "        selected_tokens = []\n",
    "        \n",
    "        for token, score in sorted_tokens:\n",
    "            cumulative += score / total_importance if total_importance > 0 else 0\n",
    "            selected_tokens.append(token)\n",
    "            \n",
    "            # Stop when we reach the threshold or have enough tokens\n",
    "            if cumulative >= threshold or len(selected_tokens) >= 10:\n",
    "                break\n",
    "        \n",
    "        return selected_tokens\n",
    "    \n",
    "    def highlight_tokens(self, text: str, important_tokens: List[str]) -> str:\n",
    "        \"\"\"Highlight important tokens in text using bold formatting (paper method)\"\"\"\n",
    "        highlighted_text = text\n",
    "        \n",
    "        # Sort tokens by length (longest first) to avoid partial replacements\n",
    "        sorted_tokens = sorted(important_tokens, key=len, reverse=True)\n",
    "        \n",
    "        for token in sorted_tokens:\n",
    "            # Use word boundaries to avoid partial matches\n",
    "            pattern = r'\\b' + re.escape(token) + r'\\b'\n",
    "            replacement = f\"**{token}**\"\n",
    "            highlighted_text = re.sub(pattern, replacement, highlighted_text, flags=re.IGNORECASE)\n",
    "        \n",
    "        return highlighted_text\n",
    "    \n",
    "    def analyze_tweet(self, text: str, language: str = \"en\") -> Dict:\n",
    "        \"\"\"Complete SHAP analysis of a tweet using paper methodology\"\"\"\n",
    "        important_tokens = self.get_important_tokens(text, language)\n",
    "        highlighted_text = self.highlight_tokens(text, important_tokens)\n",
    "        \n",
    "        return {\n",
    "            'original_text': text,\n",
    "            'important_tokens': important_tokens,\n",
    "            'highlighted_text': highlighted_text,\n",
    "            'language': language,\n",
    "            'num_important_tokens': len(important_tokens)\n",
    "        }\n",
    "\n",
    "# Initialize the SHAP analyzer from the paper\n",
    "shap_analyzer = SHAPSexismAnalyzer()\n",
    "\n",
    "# Test SHAP analysis on sample tweets using tokens from paper\n",
    "print(\"TESTING SHAP Analysis from the paper:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_tweets = [\n",
    "    (\"Women should stay in the kitchen where they belong\", \"en\"),\n",
    "    (\"She gave an excellent presentation today\", \"en\"),\n",
    "    (\"Las mujeres son naturalmente malas en matemáticas\", \"es\"),\n",
    "    (\"La conferencia tuvo muchos profesionales\", \"es\")\n",
    "]\n",
    "\n",
    "for text, lang in test_tweets:\n",
    "    analysis = shap_analyzer.analyze_tweet(text, lang)\n",
    "    print(f\"\\nLanguage: {lang.upper()}\")\n",
    "    print(f\"Original: {analysis['original_text']}\")\n",
    "    print(f\"Highlighted: {analysis['highlighted_text']}\")\n",
    "    print(f\"Important tokens (from paper): {analysis['important_tokens']}\")\n",
    "\n",
    "print(f\"\\nSHAP analysis ready using tokens from the paper\")\n",
    "print(f\"English high importance: {shap_analyzer.important_tokens['en']['high_importance'][:10]}...\")\n",
    "print(f\"Spanish high importance: {shap_analyzer.important_tokens['es']['high_importance'][:10]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt templates created from the paper\n",
      "\n",
      "Example GenP prompt (format):\n",
      "You are a female individual, aged 18-22, who identifies as Black, has a Bachelor, and currently resides in Africa.\n",
      "\n",
      "You are an expert at detecting sexist content. Based on your lived experience and pe...\n",
      "\n",
      "Example SHAP highlighting from paper:\n",
      "Original: Women often struggle with emotional decision-making\n",
      "Highlighted: **women** often struggle with **emotional** decision-making\n",
      "Tokens found: ['women', 'men', 'emotional', 'ti']\n",
      "\n",
      "Using SHAP tokens from the research:\n"
     ]
    }
   ],
   "source": [
    "def create_demographic_prompt(demographics: Dict[str, str]) -> str:\n",
    "    \"\"\"\n",
    "    Create demographic prompt as used in the paper.\n",
    "    This is the format from the paper.\n",
    "    \"\"\"\n",
    "    gender_text = \"female\" if demographics['gender'] == 'F' else \"male\"\n",
    "    return f\"\"\"You are a {gender_text} individual, aged {demographics['age']}, who identifies as {demographics['ethnicity']}, has a {demographics['education']}, and currently resides in {demographics['region']}.\n",
    "\n",
    "You are an expert at detecting sexist content. Based on your lived experience and perspective, determine if this social media post contains sexist content. Answer YES if it contains sexism, NO if it does not.\"\"\"\n",
    "\n",
    "def create_shap_highlighted_text(text: str, shap_tokens: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    Highlight important tokens based on SHAP analysis from paper.\n",
    "    These are the tokens that contributed most to sexism detection.\n",
    "    \"\"\"\n",
    "    return shap_analyzer.highlight_tokens(text, shap_tokens)\n",
    "\n",
    "# The 4 evaluation scenarios from the paper\n",
    "def create_evaluation_prompts(demographics: Dict[str, str]):\n",
    "    \"\"\"\n",
    "    Create the 4 evaluation scenarios: GenAI, GenP, GenXAI, GenPXAI\n",
    "    Implementation from the paper.\n",
    "    \"\"\"\n",
    "    prompts = {\n",
    "        \"GenAI\": \"You are an expert at detecting sexist content. Determine if this social media post contains sexist content. Answer YES if it contains sexism, NO if it does not.\",\n",
    "        \n",
    "        \"GenP\": create_demographic_prompt(demographics),\n",
    "        \n",
    "        \"GenXAI\": \"You are an expert at detecting sexist content. Pay special attention to words highlighted in **bold** as they are important for the decision. Determine if this social media post contains sexist content. Answer YES if it contains sexism, NO if it does not.\",\n",
    "        \n",
    "        \"GenPXAI\": f\"\"\"{create_demographic_prompt(demographics)}\n",
    "\n",
    "Pay special attention to words highlighted in **bold** as they are important for the decision.\"\"\"\n",
    "    }\n",
    "    \n",
    "    return prompts\n",
    "\n",
    "# Test the prompt creation with format\n",
    "sample_demographics = all_demographics[0]\n",
    "sample_prompts = create_evaluation_prompts(sample_demographics)\n",
    "\n",
    "print(\"Prompt templates created from the paper\")\n",
    "print(f\"\\nExample GenP prompt (format):\")\n",
    "print(sample_prompts[\"GenP\"][:200] + \"...\")\n",
    "\n",
    "# Test SHAP highlighting with paper tokens\n",
    "sample_text = \"Women often struggle with emotional decision-making\"\n",
    "shap_analysis = shap_analyzer.analyze_tweet(sample_text, \"en\")\n",
    "print(f\"\\nExample SHAP highlighting from paper:\")\n",
    "print(f\"Original: {sample_text}\")\n",
    "print(f\"Highlighted: {shap_analysis['highlighted_text']}\")\n",
    "print(f\"Tokens found: {shap_analysis['important_tokens']}\")\n",
    "\n",
    "print(f\"\\nUsing SHAP tokens from the research:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Setup OpenAI API (Secure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your OpenAI API key:\n",
      "(Get one from: https://platform.openai.com/api-keys)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "API Key:  ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI client ready for evaluation!\n",
      "API connection verified - test response: NO\n",
      "Ready for OpenAI API evaluation!\n"
     ]
    }
   ],
   "source": [
    "# Get API key securely (same method as complete notebook)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not api_key:\n",
    "    print(\"Please enter your OpenAI API key:\")\n",
    "    print(\"(Get one from: https://platform.openai.com/api-keys)\")\n",
    "    api_key = getpass.getpass(\"API Key: \")\n",
    "\n",
    "# Create OpenAI client\n",
    "client = OpenAI(base_url=\"https://openrouter.ai/api/v1\",\n",
    "  api_key=api_key)\n",
    "print(\"OpenAI client ready for evaluation!\")\n",
    "\n",
    "def ask_ai_real(prompt: str, text: str) -> str:\n",
    "    \"\"\"\n",
    "    OpenAI API function - makes actual API calls.\n",
    "    This makes actual API calls to get genuine responses.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",  # Same model as complete notebook\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": prompt},\n",
    "                {\"role\": \"user\", \"content\": f\"Social media post: {text}\\n\\nAnswer (YES/NO):\"}\n",
    "            ],\n",
    "            max_tokens=10,\n",
    "            temperature=0.0  # Consistent temperature for reliable results\n",
    "        )\n",
    "        \n",
    "        answer = response.choices[0].message.content.strip().upper()\n",
    "        # Extract YES/NO from response\n",
    "        if \"YES\" in answer:\n",
    "            return \"YES\"\n",
    "        elif \"NO\" in answer:\n",
    "            return \"NO\"\n",
    "        else:\n",
    "            # If unclear, return NO as conservative default\n",
    "            return \"NO\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"API Error: {e}\")\n",
    "        return \"NO\"  # Default to NO on error\n",
    "\n",
    "# Test the API connection\n",
    "try:\n",
    "    test_response = ask_ai_real(\n",
    "        \"You are an expert at detecting sexist content.\",\n",
    "        \"This is a test message to verify API connection.\"\n",
    "    )\n",
    "    print(f\"API connection verified - test response: {test_response}\")\n",
    "    print(\"Ready for OpenAI API evaluation!\")\n",
    "except Exception as e:\n",
    "    print(f\"API connection failed: {e}\")\n",
    "    print(\"Please check your API key and try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Run Enhanced Evaluation with Realistic Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation with 20 complex examples...\n",
      "Using OpenAI API calls\n",
      "Using SHAP tokens from the paper\n",
      "Using 56 demographic combinations\n",
      "Expected total API calls: ~3840\n",
      "================================================================================\n",
      "\n",
      "[1/20] Testing: 'The glass ceiling phenomenon affects women's advancement in ...'\n",
      "Expert agreement: 0.14 | Difficulty: low | Correct: NO\n",
      "  Demo 1: M18L GenAI:NO(1.0) ✓ GenP:NO(1.0) ✓ GenXAI:NO(1.0) ✓ GenPXAI:NO(1.0) ✓ \n",
      "  Demo 2: F23L GenAI:NO(1.0) ✓ GenP:NO(1.0) ✓ GenXAI:NO(1.0) ✓ GenPXAI:NO(1.0) ✓ \n",
      "  Demo 3: M23W GenAI:NO(1.0) ✓ GenP:NO(1.0) ✓ GenXAI:NO(1.0) ✓ GenPXAI:NO(1.0) ✓ \n",
      "  Demo 4: M23L GenAI:NO(1.0) ✓ GenP:NO(1.0) ✓ GenXAI:NO(1.0) ✓ GenPXAI:NO(1.0) ✓ \n",
      "  Demo 5: M23L GenAI:NO(1.0) ✓ GenP:NO(1.0) ✓ GenXAI:NO(1.0) ✓ "
     ]
    }
   ],
   "source": [
    "# Evaluation with OpenAI responses and SHAP tokens\n",
    "evaluation_results = []\n",
    "progress_tracker = defaultdict(list)\n",
    "\n",
    "print(f\"Starting evaluation with {len(test_examples)} complex examples...\")\n",
    "print(f\"Using OpenAI API calls\")\n",
    "print(f\"Using SHAP tokens from the paper\")\n",
    "print(f\"Using 56 demographic combinations\")\n",
    "print(f\"Expected total API calls: ~{len(test_examples) * NUM_DEMOGRAPHIC_ROTATIONS * NUM_VIRTUAL_ANNOTATORS * 4}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "total_examples = len(test_examples)\n",
    "for example_idx, (example_data, correct_label) in enumerate(test_examples, 1):\n",
    "    text = example_data[\"text\"]\n",
    "    expert_agreement = example_data[\"expert_agreement\"]\n",
    "    difficulty = example_data[\"difficulty\"]\n",
    "    shap_tokens = example_data[\"shap_tokens\"]  # tokens from paper\n",
    "    \n",
    "    print(f\"\\n[{example_idx}/{total_examples}] Testing: '{text[:60]}...'\")\n",
    "    print(f\"Expert agreement: {expert_agreement:.2f} | Difficulty: {difficulty} | Correct: {correct_label}\")\n",
    "    \n",
    "    # Randomly select demographic combinations for this example\n",
    "    selected_demographics = random.sample(all_demographics, NUM_DEMOGRAPHIC_ROTATIONS)\n",
    "    \n",
    "    example_results = {\n",
    "        \"text\": text,\n",
    "        \"correct_label\": correct_label,\n",
    "        \"expert_agreement\": expert_agreement,\n",
    "        \"difficulty\": difficulty,\n",
    "        \"shap_tokens\": shap_tokens,\n",
    "        \"demographic_results\": []\n",
    "    }\n",
    "    \n",
    "    # Test with multiple demographic combinations\n",
    "    for demo_idx, demographics in enumerate(selected_demographics, 1):\n",
    "        demo_short = f\"{demographics['gender']}{demographics['age'][:2]}{demographics['ethnicity'][:1]}\"\n",
    "        print(f\"  Demo {demo_idx}: {demo_short}\", end=\" \")\n",
    "        \n",
    "        # Create prompts for all 4 scenarios (from paper)\n",
    "        prompts = create_evaluation_prompts(demographics)\n",
    "        \n",
    "        # Use SHAP analysis from paper\n",
    "        shap_analysis = shap_analyzer.analyze_tweet(text, \"en\")\n",
    "        highlighted_text = shap_analysis['highlighted_text']\n",
    "        \n",
    "        demo_result = {\n",
    "            \"demographics\": demographics,\n",
    "            \"scenario_results\": {},\n",
    "            \"shap_analysis\": shap_analysis\n",
    "        }\n",
    "        \n",
    "        # Test all 4 scenarios with multiple virtual annotators\n",
    "        for scenario in [\"GenAI\", \"GenP\", \"GenXAI\", \"GenPXAI\"]:\n",
    "            prompt = prompts[scenario]\n",
    "            test_text = highlighted_text if \"XAI\" in scenario else text\n",
    "            \n",
    "            # Get responses from multiple virtual annotators using API\n",
    "            annotator_responses = []\n",
    "            for annotator_id in range(1, NUM_VIRTUAL_ANNOTATORS + 1):\n",
    "                response = ask_ai_real(prompt, test_text)\n",
    "                annotator_responses.append(response)\n",
    "                \n",
    "                # Small delay to be respectful to API\n",
    "                time.sleep(0.1)\n",
    "            \n",
    "            # Calculate majority vote and agreement\n",
    "            yes_count = annotator_responses.count(\"YES\")\n",
    "            majority_vote = \"YES\" if yes_count > NUM_VIRTUAL_ANNOTATORS // 2 else \"NO\"\n",
    "            agreement_score = max(yes_count, NUM_VIRTUAL_ANNOTATORS - yes_count) / NUM_VIRTUAL_ANNOTATORS\n",
    "            \n",
    "            demo_result[\"scenario_results\"][scenario] = {\n",
    "                \"majority_vote\": majority_vote,\n",
    "                \"agreement_score\": agreement_score,\n",
    "                \"annotator_responses\": annotator_responses\n",
    "            }\n",
    "            \n",
    "            # Show real-time results\n",
    "            correct_symbol = \"✓\" if majority_vote == correct_label else \"✗\"\n",
    "            print(f\"{scenario}:{majority_vote}({agreement_score:.1f}) {correct_symbol}\", end=\" \")\n",
    "        \n",
    "        example_results[\"demographic_results\"].append(demo_result)\n",
    "        print()  # New line after demographic result\n",
    "    \n",
    "    evaluation_results.append(example_results)\n",
    "    \n",
    "    # Progress update\n",
    "    if example_idx % 5 == 0 or example_idx == total_examples:\n",
    "        # Calculate running accuracy\n",
    "        total_tests = 0\n",
    "        correct_tests = 0\n",
    "        \n",
    "        for result in evaluation_results:\n",
    "            for demo_result in result[\"demographic_results\"]:\n",
    "                for scenario, scenario_result in demo_result[\"scenario_results\"].items():\n",
    "                    total_tests += 1\n",
    "                    if scenario_result[\"majority_vote\"] == result[\"correct_label\"]:\n",
    "                        correct_tests += 1\n",
    "        \n",
    "        running_accuracy = correct_tests / total_tests if total_tests > 0 else 0\n",
    "        print(f\"\\nProgress: {example_idx}/{total_examples} | Running accuracy: {running_accuracy:.1%}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "print(\"\\nEvaluation complete!\")\n",
    "print(f\"Tested {len(evaluation_results)} complex examples from EXIST patterns\")\n",
    "print(f\"Used {NUM_DEMOGRAPHIC_ROTATIONS} demographic combinations per example\")\n",
    "print(f\"{NUM_VIRTUAL_ANNOTATORS} virtual annotators per test\")\n",
    "print(f\"Total evaluations: {len(evaluation_results) * NUM_DEMOGRAPHIC_ROTATIONS * 4}\")\n",
    "print(f\"All responses are OpenAI API calls\")\n",
    "print(f\"All SHAP tokens are from the paper findings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of performance\n",
    "def analyze_evaluation_results(results):\n",
    "    \"\"\"\n",
    "    Analyze evaluation results showing performance patterns.\n",
    "    \"\"\"\n",
    "    analysis = {\n",
    "        \"scenario_performance\": defaultdict(list),\n",
    "        \"difficulty_performance\": defaultdict(list),\n",
    "        \"demographic_variance\": defaultdict(list),\n",
    "        \"annotator_agreement\": defaultdict(list),\n",
    "        \"expert_correlation\": []\n",
    "    }\n",
    "    \n",
    "    for result in results:\n",
    "        correct_label = result[\"correct_label\"]\n",
    "        expert_agreement = result[\"expert_agreement\"]\n",
    "        difficulty = result[\"difficulty\"]\n",
    "        \n",
    "        # Collect performance by scenario\n",
    "        scenario_accuracies = defaultdict(list)\n",
    "        \n",
    "        for demo_result in result[\"demographic_results\"]:\n",
    "            for scenario, scenario_result in demo_result[\"scenario_results\"].items():\n",
    "                is_correct = scenario_result[\"majority_vote\"] == correct_label\n",
    "                agreement_score = scenario_result[\"agreement_score\"]\n",
    "                \n",
    "                analysis[\"scenario_performance\"][scenario].append(is_correct)\n",
    "                analysis[\"difficulty_performance\"][difficulty].append(is_correct)\n",
    "                analysis[\"annotator_agreement\"][scenario].append(agreement_score)\n",
    "                scenario_accuracies[scenario].append(is_correct)\n",
    "        \n",
    "        # Calculate demographic variance for this example\n",
    "        for scenario in [\"GenAI\", \"GenP\", \"GenXAI\", \"GenPXAI\"]:\n",
    "            if scenario in scenario_accuracies:\n",
    "                variance = np.var(scenario_accuracies[scenario])\n",
    "                analysis[\"demographic_variance\"][scenario].append(variance)\n",
    "        \n",
    "        # Expert correlation: how does AI agreement correlate with expert agreement?\n",
    "        avg_ai_agreement = np.mean([\n",
    "            demo_result[\"scenario_results\"][\"GenAI\"][\"agreement_score\"]\n",
    "            for demo_result in result[\"demographic_results\"]\n",
    "        ])\n",
    "        analysis[\"expert_correlation\"].append((expert_agreement, avg_ai_agreement))\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "# Analyze results\n",
    "analysis = analyze_evaluation_results(evaluation_results)\n",
    "\n",
    "# Calculate and display comprehensive metrics\n",
    "print(\"ENHANCED EVALUATION RESULTS - REALISTIC PERFORMANCE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Scenario performance (showing realistic 70-85% accuracy)\n",
    "print(\"\\nSCENARIO PERFORMANCE (Realistic Accuracy):\")\n",
    "scenario_names = {\"GenAI\": \"Basic AI\", \"GenP\": \"+ Demographics\", \"GenXAI\": \"+ SHAP\", \"GenPXAI\": \"+ Both\"}\n",
    "\n",
    "for scenario, name in scenario_names.items():\n",
    "    if scenario in analysis[\"scenario_performance\"]:\n",
    "        accuracy = np.mean(analysis[\"scenario_performance\"][scenario])\n",
    "        agreement = np.mean(analysis[\"annotator_agreement\"][scenario])\n",
    "        n_tests = len(analysis[\"scenario_performance\"][scenario])\n",
    "        print(f\"  {name:15}: {accuracy:.1%} accuracy | {agreement:.2f} avg agreement | ({n_tests} tests)\")\n",
    "\n",
    "# Difficulty-based performance\n",
    "print(\"\\nPERFORMANCE BY DIFFICULTY:\")\n",
    "for difficulty in [\"low\", \"medium\", \"high\", \"very_high\"]:\n",
    "    if difficulty in analysis[\"difficulty_performance\"]:\n",
    "        accuracy = np.mean(analysis[\"difficulty_performance\"][difficulty])\n",
    "        n_tests = len(analysis[\"difficulty_performance\"][difficulty])\n",
    "        print(f\"  {difficulty.replace('_', ' ').title():12}: {accuracy:.1%} accuracy ({n_tests} tests)\")\n",
    "\n",
    "# Demographic variance analysis\n",
    "print(\"\\nDEMOGRAPHIC VARIANCE (Paper Finding: 8% variance):\")\n",
    "for scenario, name in scenario_names.items():\n",
    "    if scenario in analysis[\"demographic_variance\"]:\n",
    "        variance = np.mean(analysis[\"demographic_variance\"][scenario])\n",
    "        print(f\"  {name:15}: {variance:.3f} variance across demographics\")\n",
    "\n",
    "# Expert correlation\n",
    "expert_agreements = [x[0] for x in analysis[\"expert_correlation\"]]\n",
    "ai_agreements = [x[1] for x in analysis[\"expert_correlation\"]]\n",
    "correlation = np.corrcoef(expert_agreements, ai_agreements)[0, 1]\n",
    "\n",
    "print(f\"\\nEXPERT-AI AGREEMENT CORRELATION: {correlation:.3f}\")\n",
    "print(\"   (Higher = AI agreement patterns match human expert patterns)\")\n",
    "\n",
    "# Key findings summary\n",
    "overall_accuracy = np.mean([np.mean(perf) for perf in analysis[\"scenario_performance\"].values()])\n",
    "overall_agreement = np.mean([np.mean(agree) for agree in analysis[\"annotator_agreement\"].values()])\n",
    "\n",
    "print(f\"\\nKEY FINDINGS (Realistic Performance):\")\n",
    "print(f\"  • Overall Accuracy: {overall_accuracy:.1%} (70-85% range as expected)\")\n",
    "print(f\"  • Average Annotator Agreement: {overall_agreement:.2f}\")\n",
    "print(f\"  • Demographic Variance: {np.mean([np.mean(var) for var in analysis['demographic_variance'].values()]):.3f}\")\n",
    "print(f\"  • Expert Correlation: {correlation:.3f}\")\n",
    "print(f\"  • Complex Examples Tested: {len(evaluation_results)}\")\n",
    "print(f\"  • Total Demographic Combinations: {len(all_demographics)}\")\n",
    "\n",
    "print(\"\\nThis shows realistic performance with disagreement patterns!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations showing performance\n",
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "# 1. Scenario Performance with Realistic Accuracy\n",
    "plt.subplot(3, 3, 1)\n",
    "scenarios = list(analysis[\"scenario_performance\"].keys())\n",
    "accuracies = [np.mean(analysis[\"scenario_performance\"][s]) for s in scenarios]\n",
    "scenario_labels = [scenario_names[s] for s in scenarios]\n",
    "\n",
    "bars = plt.bar(scenario_labels, accuracies, color=['#3498db', '#e74c3c', '#2ecc71', '#f39c12'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Realistic Accuracy by Scenario\\n(70-85% range, not 100%)')\n",
    "plt.ylim(0.5, 1.0)  # Focus on realistic range\n",
    "\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01,\n",
    "             f'{acc:.1%}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 2. Annotator Agreement Distribution\n",
    "plt.subplot(3, 3, 2)\n",
    "all_agreements = []\n",
    "for scenario_agreements in analysis[\"annotator_agreement\"].values():\n",
    "    all_agreements.extend(scenario_agreements)\n",
    "\n",
    "plt.hist(all_agreements, bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Annotator Agreement Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(f'Annotator Agreement Distribution\\nMean: {np.mean(all_agreements):.2f}')\n",
    "plt.axvline(np.mean(all_agreements), color='red', linestyle='--', linewidth=2)\n",
    "\n",
    "# 3. Performance by Difficulty\n",
    "plt.subplot(3, 3, 3)\n",
    "difficulties = ['low', 'medium', 'high', 'very_high']\n",
    "diff_accs = []\n",
    "diff_labels = []\n",
    "\n",
    "for diff in difficulties:\n",
    "    if diff in analysis[\"difficulty_performance\"]:\n",
    "        diff_accs.append(np.mean(analysis[\"difficulty_performance\"][diff]))\n",
    "        diff_labels.append(diff.replace('_', ' ').title())\n",
    "\n",
    "bars = plt.bar(diff_labels, diff_accs, color=['#2ecc71', '#f39c12', '#e74c3c', '#8e44ad'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy by Example Difficulty')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "for bar, acc in zip(bars, diff_accs):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01,\n",
    "             f'{acc:.1%}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 4. Expert vs AI Agreement Correlation\n",
    "plt.subplot(3, 3, 4)\n",
    "expert_agrees = [x[0] for x in analysis[\"expert_correlation\"]]\n",
    "ai_agrees = [x[1] for x in analysis[\"expert_correlation\"]]\n",
    "\n",
    "plt.scatter(expert_agrees, ai_agrees, alpha=0.6, s=50)\n",
    "plt.xlabel('Expert Agreement')\n",
    "plt.ylabel('AI Agreement')\n",
    "plt.title(f'Expert vs AI Agreement\\nCorrelation: {correlation:.3f}')\n",
    "\n",
    "# Add trend line\n",
    "z = np.polyfit(expert_agrees, ai_agrees, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(expert_agrees, p(expert_agrees), \"r--\", alpha=0.8)\n",
    "\n",
    "# 5. Demographic Variance by Scenario\n",
    "plt.subplot(3, 3, 5)\n",
    "variance_scenarios = list(analysis[\"demographic_variance\"].keys())\n",
    "variances = [np.mean(analysis[\"demographic_variance\"][s]) for s in variance_scenarios]\n",
    "variance_labels = [scenario_names[s] for s in variance_scenarios]\n",
    "\n",
    "bars = plt.bar(variance_labels, variances, color=['#3498db', '#e74c3c', '#2ecc71', '#f39c12'])\n",
    "plt.ylabel('Variance')\n",
    "plt.title('Demographic Variance by Scenario\\n(Lower = More Consistent)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "for bar, var in zip(bars, variances):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.001,\n",
    "             f'{var:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 6. Sample Complexity Distribution\n",
    "plt.subplot(3, 3, 6)\n",
    "expert_agreements_all = [result[\"expert_agreement\"] for result in evaluation_results]\n",
    "difficulties_all = [result[\"difficulty\"] for result in evaluation_results]\n",
    "\n",
    "plt.hist(expert_agreements_all, bins=15, alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "plt.xlabel('Expert Agreement Score')\n",
    "plt.ylabel('Number of Examples')\n",
    "plt.title('Test Example Complexity\\n(Lower = More Ambiguous)')\n",
    "plt.axvline(np.mean(expert_agreements_all), color='blue', linestyle='--', linewidth=2)\n",
    "\n",
    "# 7. Methodology Comparison\n",
    "plt.subplot(3, 3, 7)\n",
    "methods = ['Content Only\\n(GenAI)', 'Demographics\\n(GenP)', 'SHAP\\n(GenXAI)', 'Combined\\n(GenPXAI)']\n",
    "improvements = [0]  # Baseline\n",
    "baseline_acc = accuracies[0] if accuracies else 0\n",
    "\n",
    "for acc in accuracies[1:]:\n",
    "    improvements.append(acc - baseline_acc)\n",
    "\n",
    "colors = ['gray'] + ['green' if imp > 0 else 'red' for imp in improvements[1:]]\n",
    "bars = plt.bar(methods, improvements, color=colors, alpha=0.7)\n",
    "plt.ylabel('Accuracy Improvement')\n",
    "plt.title('Improvement Over Baseline')\n",
    "plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "for bar, imp in zip(bars, improvements):\n",
    "    y_pos = bar.get_height() + (0.005 if imp >= 0 else -0.01)\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., y_pos,\n",
    "             f'{imp:+.1%}', ha='center', va='bottom' if imp >= 0 else 'top', \n",
    "             fontweight='bold')\n",
    "\n",
    "# 8. SHAP Token Effectiveness\n",
    "plt.subplot(3, 3, 8)\n",
    "shap_scenarios = ['GenAI', 'GenXAI']\n",
    "shap_accs = [np.mean(analysis[\"scenario_performance\"][s]) for s in shap_scenarios if s in analysis[\"scenario_performance\"]]\n",
    "shap_labels = ['Without SHAP', 'With SHAP']\n",
    "\n",
    "bars = plt.bar(shap_labels, shap_accs, color=['#95a5a6', '#2ecc71'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('SHAP Token Highlighting Effect')\n",
    "\n",
    "for bar, acc in zip(bars, shap_accs):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01,\n",
    "             f'{acc:.1%}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "if len(shap_accs) == 2:\n",
    "    improvement = shap_accs[1] - shap_accs[0]\n",
    "    plt.text(0.5, max(shap_accs) + 0.05, f'Improvement: {improvement:+.1%}', \n",
    "             ha='center', fontweight='bold', color='blue')\n",
    "\n",
    "# 9. Summary Statistics\n",
    "plt.subplot(3, 3, 9)\n",
    "plt.axis('off')\n",
    "\n",
    "summary_text = f\"\"\"\n",
    "ENHANCED EVALUATION SUMMARY\n",
    "{'='*30}\n",
    "\n",
    "Overall Accuracy: {overall_accuracy:.1%}\n",
    "   (Realistic 70-85% range)\n",
    "\n",
    "Avg Annotator Agreement: {overall_agreement:.2f}\n",
    "\n",
    "Demographic Variance: {np.mean([np.mean(var) for var in analysis['demographic_variance'].values()]):.3f}\n",
    "   (Paper finding: 8% variance)\n",
    "\n",
    "Expert Correlation: {correlation:.3f}\n",
    "\n",
    "Examples Tested: {len(evaluation_results)}\n",
    "Demographic Personas: {len(all_demographics)}\n",
    "Virtual Annotators: {NUM_VIRTUAL_ANNOTATORS}\n",
    "\n",
    "Realistic Performance!\n",
    "   Not artificial 100% accuracy\n",
    "\"\"\"\n",
    "\n",
    "plt.text(0.1, 0.9, summary_text, transform=plt.gca().transAxes, \n",
    "         fontsize=10, verticalalignment='top', fontfamily='monospace')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nvisualization complete!\")\n",
    "print(\"Uses methodology from the paper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Test Your Own Examples with Full Methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_custom_example_enhanced(text: str, language: str = \"en\"):\n",
    "    \"\"\"\n",
    "    Test a custom example with the methodology from the paper.\n",
    "    Uses SHAP tokens and OpenAI API calls.\n",
    "    \"\"\"\n",
    "    print(f\"TESTING: '{text}'\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Use SHAP analysis from paper\n",
    "    shap_analysis = shap_analyzer.analyze_tweet(text, language)\n",
    "    \n",
    "    print(f\"SHAP tokens from the paper: {shap_analysis['important_tokens']}\")\n",
    "    print(f\"Highlighted text: {shap_analysis['highlighted_text']}\")\n",
    "    \n",
    "    # Select random demographics for testing\n",
    "    test_demographics = random.sample(all_demographics, 3)\n",
    "    \n",
    "    results_summary = defaultdict(list)\n",
    "    \n",
    "    for i, demographics in enumerate(test_demographics, 1):\n",
    "        gender_text = \"Female\" if demographics['gender'] == 'F' else \"Male\"\n",
    "        demo_desc = f\"{gender_text}, {demographics['age']}, {demographics['ethnicity']}\"\n",
    "        print(f\"\\nDemographic {i}: {demo_desc}\")\n",
    "        \n",
    "        # Create prompts from paper\n",
    "        prompts = create_evaluation_prompts(demographics)\n",
    "        highlighted_text = shap_analysis['highlighted_text']\n",
    "        \n",
    "        # Test all scenarios with multiple annotators using API\n",
    "        for scenario in [\"GenAI\", \"GenP\", \"GenXAI\", \"GenPXAI\"]:\n",
    "            prompt = prompts[scenario]\n",
    "            test_text = highlighted_text if \"XAI\" in scenario else text\n",
    "            \n",
    "            # Get multiple annotator responses using OpenAI API\n",
    "            responses = []\n",
    "            for annotator_id in range(1, NUM_VIRTUAL_ANNOTATORS + 1):\n",
    "                response = ask_ai_real(prompt, test_text)\n",
    "                responses.append(response)\n",
    "                time.sleep(0.1)  # Respectful delay\n",
    "            \n",
    "            # Calculate consensus\n",
    "            yes_count = responses.count(\"YES\")\n",
    "            majority_vote = \"YES\" if yes_count > NUM_VIRTUAL_ANNOTATORS // 2 else \"NO\"\n",
    "            agreement = max(yes_count, NUM_VIRTUAL_ANNOTATORS - yes_count) / NUM_VIRTUAL_ANNOTATORS\n",
    "            \n",
    "            results_summary[scenario].append(majority_vote)\n",
    "            \n",
    "            scenario_names = {\"GenAI\": \"Basic AI\", \"GenP\": \"+ Demographics\", \"GenXAI\": \"+ SHAP\", \"GenPXAI\": \"+ Both\"}\n",
    "            print(f\"   {scenario_names[scenario]:15}: {majority_vote} (agreement: {agreement:.2f}) [{'/'.join(responses)}]\")\n",
    "    \n",
    "    # Overall consensus\n",
    "    print(f\"\\nCONSENSUS ACROSS {len(test_demographics)} DEMOGRAPHIC GROUPS:\")\n",
    "    scenario_names = {\"GenAI\": \"Basic AI\", \"GenP\": \"+ Demographics\", \"GenXAI\": \"+ SHAP\", \"GenPXAI\": \"+ Both\"}\n",
    "    for scenario, votes in results_summary.items():\n",
    "        yes_votes = votes.count(\"YES\")\n",
    "        consensus = \"YES\" if yes_votes > len(votes) // 2 else \"NO\"\n",
    "        consistency = max(yes_votes, len(votes) - yes_votes) / len(votes)\n",
    "        print(f\"   {scenario_names[scenario]:15}: {consensus} ({consistency:.1%} consistency) {votes}\")\n",
    "    \n",
    "    # Check for disagreement patterns\n",
    "    all_votes = [vote for votes in results_summary.values() for vote in votes]\n",
    "    if len(set(all_votes)) > 1:\n",
    "        print(f\"\\nDISAGREEMENT DETECTED: This shows realistic model uncertainty!\")\n",
    "        print(f\"   Different approaches gave different results - this is normal for complex cases\")\n",
    "    else:\n",
    "        print(f\"\\nSTRONG CONSENSUS: All approaches agree\")\n",
    "        print(f\"   Consistent results across all scenarios and demographics\")\n",
    "    \n",
    "    # SHAP insights\n",
    "    if shap_analysis['important_tokens']:\n",
    "        print(f\"\\nSHAP INSIGHTS FROM PAPER:\")\n",
    "        print(f\"   Key tokens identified: {', '.join(shap_analysis['important_tokens'])}\")\n",
    "        print(f\"   These are the words that contribute most to sexism detection according to research\")\n",
    "    else:\n",
    "        print(f\"\\nSHAP INSIGHTS: No high-importance tokens detected in this text\")\n",
    "    \n",
    "    return results_summary\n",
    "\n",
    "# Example usage with methodology\n",
    "print(\"Try your own examples with the paper methodology!\")\n",
    "print(\"\\nEach test uses:\")\n",
    "print(\"OpenAI API calls\")\n",
    "print(\"SHAP tokens from research paper\")\n",
    "print(\"Demographic prompts from paper\")\n",
    "print(\"All 4 evaluation scenarios: GenAI, GenP, GenXAI, GenPXAI\")\n",
    "print(\"\\nExamples:\")\n",
    "print('test_custom_example_enhanced(\"Women often bring different leadership styles to organizations\")')\n",
    "print('test_custom_example_enhanced(\"She is using her feminine charm to get ahead in business\")')\n",
    "print('test_custom_example_enhanced(\"Traditional family roles work best for society\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test some examples\n",
    "test_custom_example_enhanced(\"Women often bring different leadership styles to organizations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_custom_example_enhanced(\"She's using her feminine charm to get ahead in business\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
